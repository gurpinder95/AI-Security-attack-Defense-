{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c38b9e8",
      "metadata": {
        "id": "9c38b9e8"
      },
      "source": [
        "\n",
        "# AI Security Hands-On (Company-Style) ‚Äî **Attack ‚Üí Defense ‚Üí Reporting**\n",
        "**Minimal coding. Everything you need is here.**  \n",
        "You'll run cells top-to-bottom and only change clearly marked parameters.\n",
        "\n",
        "---\n",
        "\n",
        "## Legend\n",
        "- **üîß EDIT THIS:** You can/should change these values (model path, dataset, attack strength).\n",
        "- **‚úÖ DO NOT EDIT:** Leave this alone unless you know what you're doing.\n",
        "- **üìù REPORT:** Cells that print/save results for your report.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71b09225",
      "metadata": {
        "id": "71b09225"
      },
      "source": [
        "## 0) Quick Checklist ‚Äî What to Edit vs Not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "717a7fe1",
      "metadata": {
        "id": "717a7fe1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# üîß EDIT THIS: core knobs you'll change in most projects\n",
        "MODEL_SOURCE = \"train_scratch\"   # options: \"train_scratch\" or \"load_file\"\n",
        "MODEL_PATH   = \"/content/pretrained_model.h5\"  # used if MODEL_SOURCE == \"load_file\"\n",
        "DATASET      = \"MNIST\"           # options: \"MNIST\" or \"CIFAR10\"\n",
        "\n",
        "# Attack settings (typical edits)\n",
        "EPSILON      = 0.2               # attack strength\n",
        "PGD_STEPS    = 20                # PGD iterations\n",
        "PGD_STEP_SIZE= 0.01              # PGD step size\n",
        "\n",
        "# Training/defense knobs\n",
        "EPOCHS_BASE  = 2                 # epochs for baseline training (keep small)\n",
        "ADV_SUBSET   = 20000             # how many samples to craft adversarial data from\n",
        "EPOCHS_ADV   = 2                 # fine-tune epochs during adversarial training\n",
        "\n",
        "# Output & Logging\n",
        "SAVE_MODEL   = False             # set True if you want to save the defended model\n",
        "MODEL_SAVE_PATH = \"/content/defended_model.h5\"\n",
        "\n",
        "# ‚úÖ DO NOT EDIT: toggles for demo speed (for larger datasets, adjust carefully)\n",
        "BATCH_SIZE   = 128\n",
        "SEED         = 7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53b114bf",
      "metadata": {
        "id": "53b114bf"
      },
      "source": [
        "## 1) Install & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa5a90c8",
      "metadata": {
        "id": "fa5a90c8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ‚úÖ DO NOT EDIT: installs needed libs (safe to re-run)\n",
        "!pip -q install tensorflow==2.16.1 keras==3.3.3 adversarial-robustness-toolbox==1.18.0 numpy matplotlib scipy\n",
        "\n",
        "# ‚úÖ DO NOT EDIT: imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent\n",
        "from art.estimators.classification import KerasClassifier\n",
        "\n",
        "import scipy.ndimage as ndi\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b8c7865",
      "metadata": {
        "id": "9b8c7865"
      },
      "source": [
        "## 2) Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155a8e16",
      "metadata": {
        "id": "155a8e16"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ‚úÖ DO NOT EDIT: helper to load datasets\n",
        "def load_dataset(name):\n",
        "    if name.upper() == \"MNIST\":\n",
        "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "        x_train = (x_train.astype(\"float32\") / 255.0)[..., None]  # (N,28,28,1)\n",
        "        x_test  = (x_test.astype(\"float32\")  / 255.0)[..., None]\n",
        "        input_shape = (28,28,1)\n",
        "        num_classes = 10\n",
        "    elif name.upper() == \"CIFAR10\":\n",
        "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "        y_train = y_train.squeeze(); y_test = y_test.squeeze()\n",
        "        x_train = (x_train.astype(\"float32\") / 255.0)\n",
        "        x_test  = (x_test.astype(\"float32\")  / 255.0)\n",
        "        input_shape = (32,32,3)\n",
        "        num_classes = 10\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported dataset. Use MNIST or CIFAR10.\")\n",
        "    return (x_train, y_train, x_test, y_test, input_shape, num_classes)\n",
        "\n",
        "# üîß EDIT THIS: choose which dataset to use (set in the checklist above)\n",
        "x_train, y_train, x_test, y_test, INPUT_SHAPE, N_CLASSES = load_dataset(DATASET)\n",
        "print(\"Dataset:\", DATASET, \"-> Train:\", x_train.shape, \"Test:\", x_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81876744",
      "metadata": {
        "id": "81876744"
      },
      "source": [
        "## 3) Model ‚Äî Train or Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f25ad1",
      "metadata": {
        "id": "d6f25ad1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ‚úÖ DO NOT EDIT: example small CNNs\n",
        "def build_mnist_model(input_shape=(28,28,1), n_classes=10):\n",
        "    m = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dense(n_classes, activation=\"softmax\")\n",
        "    ])\n",
        "    m.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return m\n",
        "\n",
        "def build_cifar_model(input_shape=(32,32,3), n_classes=10):\n",
        "    m = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"), layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, activation=\"relu\"), layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, activation=\"relu\"), layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation=\"relu\"),\n",
        "        layers.Dense(n_classes, activation=\"softmax\")\n",
        "    ])\n",
        "    m.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return m\n",
        "\n",
        "# üîß EDIT THIS: decide to train small demo model or load your company's model\n",
        "if MODEL_SOURCE == \"train_scratch\":\n",
        "    if DATASET.upper() == \"MNIST\":\n",
        "        model = build_mnist_model(INPUT_SHAPE, N_CLASSES)\n",
        "    else:\n",
        "        model = build_cifar_model(INPUT_SHAPE, N_CLASSES)\n",
        "    history = model.fit(x_train, y_train, epochs=EPOCHS_BASE, batch_size=BATCH_SIZE, validation_split=0.1, verbose=1)\n",
        "elif MODEL_SOURCE == \"load_file\":\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "else:\n",
        "    raise ValueError(\"MODEL_SOURCE must be 'train_scratch' or 'load_file'\")\n",
        "\n",
        "baseline_clean_acc = model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "print(f\"üìù Baseline accuracy (clean test): {baseline_clean_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "511346a2",
      "metadata": {
        "id": "511346a2"
      },
      "source": [
        "## 4) Wrap Model for ART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "571fa816",
      "metadata": {
        "id": "571fa816"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ‚úÖ DO NOT EDIT: ART wrapper\n",
        "classifier = KerasClassifier(model=model, clip_values=(0.0, 1.0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f3645b",
      "metadata": {
        "id": "09f3645b"
      },
      "source": [
        "## 5) Red Team ‚Äî Attacks (FGSM & PGD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30827000",
      "metadata": {
        "id": "30827000"
      },
      "outputs": [],
      "source": [
        "\n",
        "# üîß EDIT THIS: attack knobs (or just use from checklist)\n",
        "fgsm = FastGradientMethod(estimator=classifier, eps=EPSILON)\n",
        "pgd  = ProjectedGradientDescent(estimator=classifier, eps=EPSILON, max_iter=PGD_STEPS, eps_step=PGD_STEP_SIZE, targeted=False)\n",
        "\n",
        "# ‚úÖ DO NOT EDIT: generate adversarial samples\n",
        "x_test_fgsm = fgsm.generate(x=x_test)\n",
        "x_test_pgd  = pgd.generate(x=x_test)\n",
        "\n",
        "# üìù REPORT: accuracy under attack\n",
        "fgsm_acc = model.evaluate(x_test_fgsm, y_test, verbose=0)[1]\n",
        "pgd_acc  = model.evaluate(x_test_pgd,  y_test, verbose=0)[1]\n",
        "print(f\"üìù FGSM (eps={EPSILON}) accuracy: {fgsm_acc:.4f}\")\n",
        "print(f\"üìù PGD  (eps={EPSILON}, steps={PGD_STEPS}) accuracy: {pgd_acc:.4f}\")\n",
        "\n",
        "# ‚úÖ DO NOT EDIT: quick visualization\n",
        "def show_pairs(x_clean, x_adv, y, n=5, title=\"Adversarial Samples\"):\n",
        "    plt.figure(figsize=(10,3))\n",
        "    for i in range(n):\n",
        "        plt.subplot(2, n, i+1); plt.imshow(x_clean[i].squeeze(), cmap=\"gray\"); plt.title(f\"Clean: {y[i]}\"); plt.axis(\"off\")\n",
        "        plt.subplot(2, n, n+i+1); plt.imshow(np.clip(x_adv[i].squeeze(), 0, 1), cmap=\"gray\"); plt.title(\"Adv\"); plt.axis(\"off\")\n",
        "    plt.suptitle(title); plt.show()\n",
        "\n",
        "# Visualize FGSM results (works best for grayscale MNIST)\n",
        "if x_test.shape[-1] == 1:\n",
        "    show_pairs(x_test, x_test_fgsm, y_test, n=5, title=\"FGSM Examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6322575d",
      "metadata": {
        "id": "6322575d"
      },
      "source": [
        "## 6) Blue Team ‚Äî Adversarial Training (Defense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dc1ecd3",
      "metadata": {
        "id": "3dc1ecd3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# üîß EDIT THIS: subset size and epochs for fast fine-tuning\n",
        "subset = min(ADV_SUBSET, len(x_train))\n",
        "x_sub, y_sub = x_train[:subset], y_train[:subset]\n",
        "\n",
        "# ‚úÖ DO NOT EDIT: craft adversarial training data with FGSM\n",
        "x_sub_adv = fgsm.generate(x=x_sub)\n",
        "x_mixed   = np.concatenate([x_sub, x_sub_adv], axis=0)\n",
        "y_mixed   = np.concatenate([y_sub, y_sub], axis=0)\n",
        "\n",
        "# ‚úÖ DO NOT EDIT: fine-tune\n",
        "model.fit(x_mixed, y_mixed, epochs=EPOCHS_ADV, batch_size=BATCH_SIZE, verbose=1)\n",
        "\n",
        "# üìù REPORT: post-defense metrics\n",
        "post_clean_acc = model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "post_fgsm_acc  = model.evaluate(x_test_fgsm, y_test, verbose=0)[1]\n",
        "post_pgd_acc   = model.evaluate(x_test_pgd,  y_test, verbose=0)[1]\n",
        "\n",
        "print(f\"üìù After adversarial training ‚Üí Clean: {post_clean_acc:.4f}, FGSM: {post_fgsm_acc:.4f}, PGD: {post_pgd_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f1f15d",
      "metadata": {
        "id": "06f1f15d"
      },
      "source": [
        "## 7) Blue Team ‚Äî Simple Preprocessing (Denoising)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192a1c17",
      "metadata": {
        "id": "192a1c17"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ‚úÖ DO NOT EDIT: simple median filter defense (toy demo)\n",
        "def denoise_batch(x):\n",
        "    x_d = np.empty_like(x)\n",
        "    # handle grayscale or RGB\n",
        "    if x.shape[-1] == 1:\n",
        "        for i in range(len(x)):\n",
        "            x_d[i,...,0] = ndi.median_filter(x[i,...,0], size=3)\n",
        "    else:\n",
        "        for i in range(len(x)):\n",
        "            for c in range(x.shape[-1]):\n",
        "                x_d[i,...,c] = ndi.median_filter(x[i,...,c], size=3)\n",
        "    return x_d\n",
        "\n",
        "x_test_pgd_denoised = denoise_batch(x_test_pgd)\n",
        "denoised_acc = model.evaluate(x_test_pgd_denoised, y_test, verbose=0)[1]\n",
        "print(f\"üìù PGD accuracy after denoising: {denoised_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "094521c3",
      "metadata": {
        "id": "094521c3"
      },
      "source": [
        "## 8) Save (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d61820d",
      "metadata": {
        "id": "3d61820d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# üîß EDIT THIS: save the defended model if needed\n",
        "if SAVE_MODEL:\n",
        "    model.save(MODEL_SAVE_PATH)\n",
        "    print(\"Saved defended model to:\", MODEL_SAVE_PATH)\n",
        "else:\n",
        "    print(\"Skipping save (set SAVE_MODEL=True to enable).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fec4662",
      "metadata": {
        "id": "4fec4662"
      },
      "source": [
        "## 9) Final Report Summary (Copy-Paste into your doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35859691",
      "metadata": {
        "id": "35859691"
      },
      "outputs": [],
      "source": [
        "\n",
        "report = {\n",
        "    \"Dataset\": DATASET,\n",
        "    \"Baseline clean accuracy\": float(baseline_clean_acc),\n",
        "    \"FGSM acc (pre-defense)\": float(fgsm_acc),\n",
        "    \"PGD acc (pre-defense)\": float(pgd_acc),\n",
        "    \"Clean acc (post adv training)\": float(post_clean_acc),\n",
        "    \"FGSM acc (post adv training)\": float(post_fgsm_acc),\n",
        "    \"PGD acc (post adv training)\": float(post_pgd_acc),\n",
        "    \"PGD acc (after denoising)\": float(denoised_acc),\n",
        "    \"FGSM epsilon\": float(EPSILON),\n",
        "    \"PGD steps\": int(PGD_STEPS),\n",
        "    \"PGD step size\": float(PGD_STEP_SIZE),\n",
        "    \"Adv subset used\": int(subset),\n",
        "    \"Epochs (baseline/adv)\": f\"{EPOCHS_BASE}/{EPOCHS_ADV}\"\n",
        "}\n",
        "for k,v in report.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "print(\"\\nMITRE ATLAS Mapping (Conceptual)\")\n",
        "print(\"- Evasion ‚Üí Adversarial Examples (FGSM/PGD)\")\n",
        "print(\"- Mitigations: Adversarial training, input transforms (denoising), monitoring for distribution shift\")\n",
        "print(\"- Recommendation: Gate releases on minimum robustness threshold; automate in CI/CD\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}